<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>✨✨✨ WLB! WLB! WLB! ✨✨✨😶‍🌫️</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="✨✨✨ WLB! WLB! WLB! ✨✨✨😶‍🌫️">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="✨✨✨ WLB! WLB! WLB! ✨✨✨😶‍🌫️">
<meta property="og:locale">
<meta property="article:author" content="EvelynUU">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="✨✨✨ WLB! WLB! WLB! ✨✨✨😶‍🌫️" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/fork-awesome@1.2.0/css/fork-awesome.min.css">

<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">✨✨✨ WLB! WLB! WLB! ✨✨✨😶‍🌫️</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">重要的事情说三遍</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-index" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/01/01/index/" class="article-date">
  <time class="dt-published" datetime="2021-01-01T08:00:00.000Z" itemprop="datePublished">2021-01-01</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/01/01/index/">Welcome to UEvelyn&#39;s blog</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="关于我"><a href="#关于我" class="headerlink" title="关于我"></a>关于我</h2><p>WLB爱好者，国家一级打退堂鼓选手（bushi<br>我是UEvelyn，专注于前后端技术栈，CI&#x2F;CD自动化，自动化测试，计算机视觉和深度学习领域。</p>
<h2 id="关于博客"><a href="#关于博客" class="headerlink" title="关于博客"></a>关于博客</h2><p>本来没想过建站的，之前工作都是在内网写confluence文档，记OneNote。<br>然后就GG了，裁员很突然以及没有任何准备的被锁了所有权限，现在全凭记忆复盘以前的工作（此时回想起曾经老师的谆谆教诲：“备份！备份！”🥲<br>悔不当初，好在这么些年下来还是有记一些东西的。</p>
<h2 id="关于本站"><a href="#关于本站" class="headerlink" title="关于本站"></a>关于本站</h2><p>会持续更新，包括但不限于概念原理、编程、算法、系统设计、工具使用等内容。<br>有道云笔记&#x2F;WPS文档&#x2F;线下笔记持续更新&#x2F;迁移中……<br>Archive随机，技术栈Tag归类, 欢迎Follow! (虽然大概率没什么人Follow…🤫)</p>
<h2 id="联系我"><a href="#联系我" class="headerlink" title="联系我"></a>联系我</h2><p>面经、职业建议、合作咨询、技术交流等请联系：<br>📧 邮箱：<a href="mailto:&#x73;&#104;&#117;&#110;&#105;&#110;&#x67;&#69;&#118;&#x65;&#x6c;&#x79;&#x6e;&#x40;&#103;&#x6d;&#97;&#x69;&#x6c;&#46;&#99;&#111;&#x6d;">&#x73;&#104;&#117;&#110;&#105;&#110;&#x67;&#69;&#118;&#x65;&#x6c;&#x79;&#x6e;&#x40;&#103;&#x6d;&#97;&#x69;&#x6c;&#46;&#99;&#111;&#x6d;</a><br>(其实也不怎么看邮件…🫠)</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/01/01/index/" data-id="cmbs36xuo0000ywsde99ihwx1" data-title="Welcome to UEvelyn&#39;s blog" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
</article>



  
    <article id="post-python_doc/pytorch/001-torch-normal-used-function" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/01/11/python_doc/pytorch/001-torch-normal-used-function/" class="article-date">
  <time class="dt-published" datetime="2021-01-11T08:59:22.000Z" itemprop="datePublished">2021-01-11</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Pytorch/">Pytorch</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/01/11/python_doc/pytorch/001-torch-normal-used-function/">001-torch normal used function</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">## 1. 卷积层</span></span><br><span class="line"></span><br><span class="line"><span class="section">### `torch.nn.Conv2d`</span></span><br><span class="line">二维卷积层  </span><br><span class="line">输入的尺度是<span class="code">`(N, Cin, H, W)`</span>，输出尺度<span class="code">`(N, Cout, Hout, Wout)`</span></span><br><span class="line"></span><br><span class="line"><span class="code">```python</span></span><br><span class="line"><span class="code">nn.Conv2d(</span></span><br><span class="line"><span class="code">    in_channels, </span></span><br><span class="line"><span class="code">    out_channels, </span></span><br><span class="line"><span class="code">    kernel_size, </span></span><br><span class="line"><span class="code">    stride=1, </span></span><br><span class="line"><span class="code">    padding=0, </span></span><br><span class="line"><span class="code">    dilation=1, </span></span><br><span class="line"><span class="code">    groups=1, </span></span><br><span class="line"><span class="code">    bias=True</span></span><br><span class="line"><span class="code">)</span></span><br></pre></td></tr></table></figure>

<p><strong>Parameters:</strong></p>
<ul>
<li><code>in_channels</code> (int) - 输入信号的通道数</li>
<li><code>out_channels</code> (int) - 卷积产生的通道数</li>
<li><code>kernel_size</code> (int or tuple) - 卷积核的尺寸</li>
<li><code>stride</code> (int or tuple, optional) - 卷积步长，默认为1</li>
<li><code>padding</code> (int or tuple, optional) - 输入的每一条边补充0的层数，默认为0</li>
<li><code>dilation</code> (int or tuple, optional) - 卷积核元素之间的间距，默认为1</li>
<li><code>groups</code> (int, optional) - 从输入通道到输出通道的阻塞连接数，默认为1</li>
<li><code>bias</code> (bool, optional) - 如果bias&#x3D;True，添加可学习的偏置到输出中</li>
</ul>
<hr>
<h3 id="torch-nn-ConvTranspose2d"><a href="#torch-nn-ConvTranspose2d" class="headerlink" title="torch.nn.ConvTranspose2d"></a><code>torch.nn.ConvTranspose2d</code></h3><p>对由多个输入平面组成的输入图像应用二维转置卷积操作</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">nn.ConvTranspose2d(</span><br><span class="line">    in_channels, </span><br><span class="line">    out_channels, </span><br><span class="line">    kernel_size, </span><br><span class="line">    stride=<span class="number">1</span>, </span><br><span class="line">    padding=<span class="number">0</span>, </span><br><span class="line">    output_padding=<span class="number">0</span>, </span><br><span class="line">    groups=<span class="number">1</span>, </span><br><span class="line">    bias=<span class="literal">True</span>, </span><br><span class="line">    dilation=<span class="number">1</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p><strong>Parameters:</strong></p>
<ul>
<li><code>in_channels</code> (int) - 输入信号的通道数</li>
<li><code>out_channels</code> (int) - 卷积产生的通道数</li>
<li><code>kernel_size</code> (int or tuple) - 卷积核的大小</li>
<li><code>stride</code> (int or tuple, optional) - 卷积步长</li>
<li><code>padding</code> (int or tuple, optional) - 输入的每一条边补充<code>padding = kernel - 1 - padding</code>，即<code>(kernel_size - 1)/2</code>个0的层数</li>
<li><code>output_padding</code> (int or tuple, optional) - 在输出的每一个维度的一边补充0的层数</li>
<li><code>dilation</code> (int or tuple, optional) - 卷积核元素之间的间距</li>
<li><code>groups</code> (int, optional) - 从输入通道到输出通道的阻塞连接数</li>
<li><code>bias</code> (bool, optional) - 如果bias&#x3D;True，添加偏置</li>
</ul>
<hr>
<h2 id="torch-utils-data-DataLoader"><a href="#torch-utils-data-DataLoader" class="headerlink" title="torch.utils.data.DataLoader"></a><code>torch.utils.data.DataLoader</code></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">torch.utils.data.DataLoader(</span><br><span class="line">    dataset,</span><br><span class="line">    batch_size=<span class="number">1</span>,</span><br><span class="line">    shuffle=<span class="literal">False</span>,</span><br><span class="line">    sampler=<span class="literal">None</span>,</span><br><span class="line">    batch_sampler=<span class="literal">None</span>,</span><br><span class="line">    num_workers=<span class="number">0</span>,</span><br><span class="line">    collate_fn=<span class="literal">None</span>,</span><br><span class="line">    pin_memory=<span class="literal">False</span>,</span><br><span class="line">    drop_last=<span class="literal">False</span>,</span><br><span class="line">    timeout=<span class="number">0</span>,</span><br><span class="line">    worker_init_fn=<span class="literal">None</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p><strong>Parameters:</strong></p>
<ul>
<li><code>dataset</code> (Dataset): 传入的数据集</li>
<li><code>batch_size</code> (int, optional): 每个batch有多少个样本</li>
<li><code>shuffle</code> (bool, optional): 在每个epoch开始的时候，对数据进行重新排序</li>
<li><code>sampler</code> (Sampler, optional): 自定义从数据集中取样本的策略（与shuffle互斥）</li>
<li><code>batch_sampler</code> (Sampler, optional): 与sampler类似，但一次只返回一个batch的indices（与batch_size&#x2F;shuffle&#x2F;sampler互斥）</li>
<li><code>num_workers</code> (int, optional): 处理data loading的进程数（0表示在主进程加载）</li>
<li><code>collate_fn</code> (callable, optional): 将list的sample组成mini-batch的函数</li>
<li><code>pin_memory</code> (bool, optional): 设置为True时会将tensors拷贝到CUDA固定内存中</li>
<li><code>drop_last</code> (bool, optional): 是否丢弃最后一个不完整的batch（默认为False）</li>
<li><code>timeout</code> (numeric, optional): 收集batch的等待时间（&gt;&#x3D;0）</li>
<li><code>worker_init_fn</code> (callable, optional): 每个worker的初始化函数</li>
</ul>
<hr>
<h2 id="Torchvision-Transforms"><a href="#Torchvision-Transforms" class="headerlink" title="Torchvision Transforms"></a>Torchvision Transforms</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">transforms.Compose([</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize(mean, std)</span><br><span class="line">])</span><br></pre></td></tr></table></figure>

<ol>
<li><p><strong><code>torchvision.transforms.Compose()</code></strong><br>主要作用是串联多个图片变换的操作</p>
</li>
<li><p><strong><code>torchvision.transforms.ToTensor()</code></strong>  </p>
<ul>
<li>将shape为<code>(H, W, C)</code>的numpy.ndarray或PIL Image转为shape为<code>(C, H, W)</code>的tensor</li>
<li>将数值归一化到[0,1]（直接除以255）</li>
</ul>
</li>
<li><p><strong><code>torchvision.transforms.Normalize()</code></strong><br>对每个通道执行：<code>image = (image - mean) / std</code><br>（ToTensor把0-255变换到0-1，Normalize再把0-1变换到(-1,1)）</p>
</li>
</ol>
<pre><code>
</code></pre>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/01/11/python_doc/pytorch/001-torch-normal-used-function/" data-id="cmbs36xvb002mywsd4on47vn1" data-title="001-torch normal used function" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Pytorch/" rel="tag">Pytorch</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-python_doc/pytorch/002-tensors-basic" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/01/12/python_doc/pytorch/002-tensors-basic/" class="article-date">
  <time class="dt-published" datetime="2021-01-12T09:06:19.000Z" itemprop="datePublished">2021-01-12</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Pytorch/">Pytorch</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/01/12/python_doc/pytorch/002-tensors-basic/">002-tensors basic</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="section"># PyTorch 张量基础</span></span><br><span class="line"></span><br><span class="line"><span class="section">## 张量简介</span></span><br><span class="line">张量是一种特殊的数据结构，与数组和矩阵非常相似。在PyTorch中，我们使用张量对模型的输入和输出以及模型的参数进行编码。</span><br><span class="line"></span><br><span class="line"><span class="section">## 基本操作</span></span><br><span class="line"></span><br><span class="line"><span class="section">### 创建张量</span></span><br><span class="line"><span class="code">```python</span></span><br><span class="line"><span class="code">import torch</span></span><br><span class="line"><span class="code">import numpy as np</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code"># 从随机数据和全1数据创建张量</span></span><br><span class="line"><span class="code">shape = (2, 3)</span></span><br><span class="line"><span class="code">rand_tensor = torch.rand(shape)  # 随机张量</span></span><br><span class="line"><span class="code">ones_tensor = torch.ones(shape)  # 全1张量</span></span><br></pre></td></tr></table></figure>

<h3 id="张量属性"><a href="#张量属性" class="headerlink" title="张量属性"></a>张量属性</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Shape of tensor: <span class="subst">&#123;rand_tensor.shape&#125;</span>&quot;</span>)  <span class="comment"># 形状</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Datatype of tensor: <span class="subst">&#123;rand_tensor.dtype&#125;</span>&quot;</span>)  <span class="comment"># 数据类型</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Device tensor is stored on: <span class="subst">&#123;rand_tensor.device&#125;</span>&quot;</span>)  <span class="comment"># 存储设备</span></span><br></pre></td></tr></table></figure>

<h3 id="索引和切片"><a href="#索引和切片" class="headerlink" title="索引和切片"></a>索引和切片</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor = torch.ones(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">tensor[:, <span class="number">1</span>] = <span class="number">0</span>  <span class="comment"># 将第1列所有元素设为0</span></span><br></pre></td></tr></table></figure>

<h3 id="张量连接"><a href="#张量连接" class="headerlink" title="张量连接"></a>张量连接</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t1 = torch.cat([tensor, tensor, tensor], dim=<span class="number">1</span>)  <span class="comment"># 沿维度1连接</span></span><br></pre></td></tr></table></figure>

<h2 id="张量运算"><a href="#张量运算" class="headerlink" title="张量运算"></a>张量运算</h2><h3 id="元素级乘法"><a href="#元素级乘法" class="headerlink" title="元素级乘法"></a>元素级乘法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 两种等价写法</span></span><br><span class="line"><span class="built_in">print</span>(tensor.mul(tensor))  <span class="comment"># 方法形式</span></span><br><span class="line"><span class="built_in">print</span>(tensor * tensor)     <span class="comment"># 运算符形式</span></span><br></pre></td></tr></table></figure>

<h3 id="矩阵乘法"><a href="#矩阵乘法" class="headerlink" title="矩阵乘法"></a>矩阵乘法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 两种等价写法</span></span><br><span class="line"><span class="built_in">print</span>(tensor.matmul(tensor.T))  <span class="comment"># 方法形式</span></span><br><span class="line"><span class="built_in">print</span>(tensor @ tensor.T)        <span class="comment"># 运算符形式</span></span><br></pre></td></tr></table></figure>

<h3 id="原地操作（In-place）"><a href="#原地操作（In-place）" class="headerlink" title="原地操作（In-place）"></a>原地操作（In-place）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor.add_(<span class="number">5</span>)  <span class="comment"># 带_后缀的操作会修改原张量</span></span><br></pre></td></tr></table></figure>
<p>注意：原地操作可以节省内存，但在计算导数时可能会出现问题，因此不鼓励使用。</p>
<h2 id="与NumPy互转"><a href="#与NumPy互转" class="headerlink" title="与NumPy互转"></a>与NumPy互转</h2><h3 id="张量转NumPy数组"><a href="#张量转NumPy数组" class="headerlink" title="张量转NumPy数组"></a>张量转NumPy数组</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t = torch.ones(<span class="number">5</span>)</span><br><span class="line">n = t.numpy()  <span class="comment"># 转为NumPy数组</span></span><br></pre></td></tr></table></figure>

<h3 id="NumPy数组转张量"><a href="#NumPy数组转张量" class="headerlink" title="NumPy数组转张量"></a>NumPy数组转张量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">n = np.ones(<span class="number">5</span>)</span><br><span class="line">t = torch.from_numpy(n)  <span class="comment"># 转为PyTorch张量</span></span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/01/12/python_doc/pytorch/002-tensors-basic/" data-id="cmbs36xve002sywsd3bqvd1gt" data-title="002-tensors basic" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Pytorch/" rel="tag">Pytorch</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-python_doc/pytorch/003-torch.autograd" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/01/14/python_doc/pytorch/003-torch.autograd/" class="article-date">
  <time class="dt-published" datetime="2021-01-14T09:09:53.000Z" itemprop="datePublished">2021-01-14</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Pytorch/">Pytorch</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/01/14/python_doc/pytorch/003-torch.autograd/">003-torch.autograd</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="section"># PyTorch Autograd 详解</span></span><br><span class="line"></span><br><span class="line"><span class="section">## 背景介绍</span></span><br><span class="line"><span class="code">`torch.autograd`</span>是PyTorch的自动微分引擎，为神经网络训练提供支持。</span><br><span class="line"></span><br><span class="line">神经网络(NN)是在输入数据上执行的嵌套函数集合，这些函数由参数（权重和偏差）定义，在PyTorch中存储在张量中。</span><br><span class="line"></span><br><span class="line">训练NN分为两个步骤：</span><br><span class="line"><span class="bullet">1.</span> <span class="strong">**前向传播**</span>：NN对输出做出最佳猜测</span><br><span class="line"><span class="bullet">2.</span> <span class="strong">**反向传播**</span>：NN根据误差调整参数，收集误差导数并使用梯度下降优化参数</span><br><span class="line"></span><br><span class="line"><span class="section">## Autograd内部机理</span></span><br><span class="line"></span><br><span class="line">![<span class="string">Autograd流程示意图</span>](<span class="link">../../../images/torch001.png</span>)</span><br><span class="line"></span><br><span class="line">实现autograd依赖于两种数据类型：</span><br><span class="line"><span class="bullet">-</span> <span class="code">`Variable`</span>：包装tensor数据，包含额外属性：</span><br><span class="line"><span class="bullet">  -</span> <span class="code">`data`</span>：存储的tensor数据</span><br><span class="line"><span class="bullet">  -</span> <span class="code">`grad`</span>：存储梯度</span><br><span class="line"><span class="bullet">  -</span> <span class="code">`creator`</span>：创建此Variable的Function</span><br><span class="line"></span><br><span class="line">工作流程：</span><br><span class="line"><span class="bullet">1.</span> 输入Variable经过操作(operation)生成输出Variable</span><br><span class="line"><span class="bullet">2.</span> 每个操作自动生成对应的Function实例</span><br><span class="line"><span class="bullet">3.</span> 反向传播时，Function自动计算梯度并存储在grad属性中</span><br><span class="line"></span><br><span class="line"><span class="strong">**重要概念**</span>：</span><br><span class="line"><span class="bullet">-</span> 只有creator为null的变量（叶子节点）才能返回导数</span><br><span class="line"><span class="bullet">-</span> 中间变量的grad为0</span><br><span class="line"></span><br><span class="line"><span class="section">## 使用案例</span></span><br><span class="line"></span><br><span class="line"><span class="section">### 1. 基本梯度采集</span></span><br><span class="line"></span><br><span class="line"><span class="code">```python</span></span><br><span class="line"><span class="code">import torch</span></span><br><span class="line"><span class="code">import torchvision</span></span><br><span class="line"><span class="code">import numpy as np</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code"># 创建需要跟踪梯度的张量</span></span><br><span class="line"><span class="code">a = torch.tensor([2., 3.], requires_grad=True)</span></span><br><span class="line"><span class="code">b = torch.tensor([6., 4.], requires_grad=True)</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code"># 定义计算图</span></span><br><span class="line"><span class="code">Q = 3*a**3 - b**2</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code"># 反向传播（只能对标量输出）</span></span><br><span class="line"><span class="code">Q.sum().backward()  # 或使用 Q.backward(gradient=torch.tensor([1., 1.]))</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code"># 验证梯度</span></span><br><span class="line"><span class="code">print(9*a**2 == a.grad)  # tensor([True, True])</span></span><br><span class="line"><span class="code">print(-2*b == b.grad)    # tensor([True, True])</span></span><br></pre></td></tr></table></figure>

<h3 id="2-在神经网络中的应用"><a href="#2-在神经网络中的应用" class="headerlink" title="2. 在神经网络中的应用"></a>2. 在神经网络中的应用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载预训练模型</span></span><br><span class="line">model = torchvision.models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line">data = torch.rand(<span class="number">1</span>, <span class="number">3</span>, <span class="number">64</span>, <span class="number">64</span>)  <span class="comment"># 模拟输入图像</span></span><br><span class="line">labels = torch.rand(<span class="number">1</span>, <span class="number">1000</span>)     <span class="comment"># 模拟标签</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 前向传播</span></span><br><span class="line">prediction = model(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算损失并反向传播</span></span><br><span class="line">loss = (prediction - labels).<span class="built_in">sum</span>()</span><br><span class="line">loss.backward()  <span class="comment"># 自动计算梯度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用优化器更新参数</span></span><br><span class="line">optim = torch.optim.SGD(</span><br><span class="line">    model.parameters(), </span><br><span class="line">    lr=<span class="number">1e-2</span>,      <span class="comment"># 学习率0.01</span></span><br><span class="line">    momentum=<span class="number">0.9</span>  <span class="comment"># 动量</span></span><br><span class="line">)</span><br><span class="line">optim.step()      <span class="comment"># 执行梯度下降</span></span><br></pre></td></tr></table></figure>

<h2 id="重要注意事项"><a href="#重要注意事项" class="headerlink" title="重要注意事项"></a>重要注意事项</h2><ol>
<li><code>backward()</code>只能对标量输出调用</li>
<li>中间变量的grad为0，只有叶子节点能获得梯度</li>
<li>优化器通过<code>.step()</code>方法更新参数</li>
<li>每次反向传播前需要清空梯度（可通过<code>optim.zero_grad()</code>实现）</li>
</ol>
<blockquote>
<p>提示：使用前需确保已安装torchvision（<code>pip install torchvision</code>）<br>&#96;&#96;&#96;</p>
</blockquote>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/01/14/python_doc/pytorch/003-torch.autograd/" data-id="cmbs36xvg0035ywsdh0m43tg6" data-title="003-torch.autograd" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Pytorch/" rel="tag">Pytorch</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-python_doc/pytorch/004-neural network" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/01/14/python_doc/pytorch/004-neural%20network/" class="article-date">
  <time class="dt-published" datetime="2021-01-14T14:09:53.000Z" itemprop="datePublished">2021-01-14</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Pytorch/">Pytorch</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/01/14/python_doc/pytorch/004-neural%20network/">004-neural network</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="section"># PyTorch 神经网络构建指南</span></span><br><span class="line"></span><br><span class="line"><span class="section">## 神经网络构建基础</span></span><br><span class="line"></span><br><span class="line">PyTorch 使用 <span class="code">`torch.nn`</span> 程序包构建神经网络：</span><br><span class="line"><span class="bullet">-</span> 基于 <span class="code">`autograd`</span> 定义和区分模型</span><br><span class="line"><span class="bullet">-</span> <span class="code">`nn.Module`</span> 包含：</span><br><span class="line"><span class="bullet">  -</span> 多个网络层</span><br><span class="line"><span class="bullet">  -</span> <span class="code">`forward(input)`</span> 方法（返回输出）</span><br><span class="line"></span><br><span class="line"><span class="section">## 案例1：定义网络</span></span><br><span class="line"></span><br><span class="line"><span class="code">```python</span></span><br><span class="line"><span class="code">import torch</span></span><br><span class="line"><span class="code">import torch.nn as nn</span></span><br><span class="line"><span class="code">import torch.nn.functional as F</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code">class Net(nn.Module):</span></span><br><span class="line"><span class="code">    def __init__(self):</span></span><br><span class="line"><span class="code">        super(Net, self).__init__()</span></span><br><span class="line"><span class="code">        # 定义网络层</span></span><br><span class="line"><span class="code">        self.conv1 = nn.Conv2d(1, 6, 3)     # 1输入通道，6输出通道，3x3卷积核</span></span><br><span class="line"><span class="code">        self.conv2 = nn.Conv2d(6, 16, 3)    # 6输入通道，16输出通道，3x3卷积核</span></span><br><span class="line"><span class="code">        self.fc1 = nn.Linear(16*6*6, 120)   # 全连接层 (16*6*6 -&gt; 120)</span></span><br><span class="line"><span class="code">        self.fc2 = nn.Linear(120, 84)       # 全连接层 (120 -&gt; 84)</span></span><br><span class="line"><span class="code">        self.fc3 = nn.Linear(84, 10)        # 全连接层 (84 -&gt; 10)</span></span><br><span class="line"><span class="code">    </span></span><br><span class="line"><span class="code">    def forward(self, x):</span></span><br><span class="line"><span class="code">        # 前向传播</span></span><br><span class="line"><span class="code">        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))  # 卷积+ReLU+2x2最大池化</span></span><br><span class="line"><span class="code">        x = F.max_pool2d(F.relu(self.conv2(x)), 2)       # 卷积+ReLU+2x2最大池化</span></span><br><span class="line"><span class="code">        x = x.view(-1, self.num_flat_features(x))         # 展平</span></span><br><span class="line"><span class="code">        x = F.relu(self.fc1(x))                           # 全连接+ReLU</span></span><br><span class="line"><span class="code">        x = F.relu(self.fc2(x))                           # 全连接+ReLU</span></span><br><span class="line"><span class="code">        x = self.fc3(x)                                   # 输出层</span></span><br><span class="line"><span class="code">        return x</span></span><br><span class="line"><span class="code">    </span></span><br><span class="line"><span class="code">    def num_flat_features(self, x):</span></span><br><span class="line"><span class="code">        # 计算展平后的特征数量</span></span><br><span class="line"><span class="code">        size = x.size()[1:]  # 除批量维度外的所有维度</span></span><br><span class="line"><span class="code">        num_features = 1</span></span><br><span class="line"><span class="code">        for s in size:</span></span><br><span class="line"><span class="code">            num_features *= s</span></span><br><span class="line"><span class="code">        return num_features</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code"># 实例化网络</span></span><br><span class="line"><span class="code">net = Net()</span></span><br><span class="line"><span class="code">print(net)</span></span><br></pre></td></tr></table></figure>

<h3 id="重要说明："><a href="#重要说明：" class="headerlink" title="重要说明："></a>重要说明：</h3><ol>
<li><strong>自动反向传播</strong>：只需定义 <code>forward</code> 函数，<code>backward</code> 会自动通过 <code>autograd</code> 计算梯度</li>
<li><strong>小批量支持</strong>：<code>torch.nn</code> 仅支持小批量输入，不支持单个样本<ul>
<li>例如：<code>nn.Conv2d</code> 需要 4D 张量输入格式：<code>nSamples × nChannels × Height × Width</code></li>
</ul>
</li>
<li><strong>网络层说明</strong>：<ul>
<li><code>nn.Conv2d</code>：二维卷积层</li>
<li><code>nn.Linear</code>：全连接层（仿射变换 y &#x3D; Wx + b）</li>
<li><code>F.relu</code>：ReLU激活函数</li>
<li><code>F.max_pool2d</code>：二维最大池化</li>
</ul>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/01/14/python_doc/pytorch/004-neural%20network/" data-id="cmbs36xvg0036ywsd2ld99l4n" data-title="004-neural network" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Pytorch/" rel="tag">Pytorch</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-python_doc/pytorch/005-model training code" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/02/07/python_doc/pytorch/005-model%20training%20code/" class="article-date">
  <time class="dt-published" datetime="2021-02-07T09:13:28.000Z" itemprop="datePublished">2021-02-07</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/Pytorch/">Pytorch</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/02/07/python_doc/pytorch/005-model%20training%20code/">005-model training code</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="section"># PyTorch 图像分类器训练指南</span></span><br><span class="line"></span><br><span class="line"><span class="section">## CIFAR100 图像分类训练</span></span><br><span class="line"></span><br><span class="line"><span class="section">### 1. 加载并规范化数据集</span></span><br><span class="line"></span><br><span class="line"><span class="code">```python</span></span><br><span class="line"><span class="code">import torch</span></span><br><span class="line"><span class="code">import torchvision</span></span><br><span class="line"><span class="code">import torchvision.transforms as transforms</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code"># 定义数据转换</span></span><br><span class="line"><span class="code">transform = transforms.Compose([</span></span><br><span class="line"><span class="code">    transforms.ToTensor(),</span></span><br><span class="line"><span class="code">    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))</span></span><br><span class="line"><span class="code">])</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code"># 加载训练集</span></span><br><span class="line"><span class="code">trainset = torchvision.datasets.CIFAR100(</span></span><br><span class="line"><span class="code">    root=&#x27;./data&#x27;, </span></span><br><span class="line"><span class="code">    train=True,</span></span><br><span class="line"><span class="code">    download=True, </span></span><br><span class="line"><span class="code">    transform=transform</span></span><br><span class="line"><span class="code">)</span></span><br><span class="line"><span class="code">trainloader = torch.utils.data.DataLoader(</span></span><br><span class="line"><span class="code">    trainset, </span></span><br><span class="line"><span class="code">    batch_size=4,</span></span><br><span class="line"><span class="code">    shuffle=True, </span></span><br><span class="line"><span class="code">    num_workers=2</span></span><br><span class="line"><span class="code">)</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code"># 加载测试集</span></span><br><span class="line"><span class="code">testset = torchvision.datasets.CIFAR100(</span></span><br><span class="line"><span class="code">    root=&#x27;./data&#x27;, </span></span><br><span class="line"><span class="code">    train=False,</span></span><br><span class="line"><span class="code">    download=True, </span></span><br><span class="line"><span class="code">    transform=transform</span></span><br><span class="line"><span class="code">)</span></span><br><span class="line"><span class="code">testloader = torch.utils.data.DataLoader(</span></span><br><span class="line"><span class="code">    testset, </span></span><br><span class="line"><span class="code">    batch_size=4,</span></span><br><span class="line"><span class="code">    shuffle=False, </span></span><br><span class="line"><span class="code">    num_workers=2</span></span><br><span class="line"><span class="code">)</span></span><br></pre></td></tr></table></figure>

<h3 id="2-定义卷积神经网络"><a href="#2-定义卷积神经网络" class="headerlink" title="2. 定义卷积神经网络"></a>2. 定义卷积神经网络</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">6</span>, <span class="number">5</span>)          <span class="comment"># 3输入通道，6输出通道，5x5卷积核</span></span><br><span class="line">        <span class="variable language_">self</span>.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)           <span class="comment"># 2x2最大池化</span></span><br><span class="line">        <span class="variable language_">self</span>.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)         <span class="comment"># 6输入通道，16输出通道，5x5卷积核</span></span><br><span class="line">        <span class="variable language_">self</span>.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)    <span class="comment"># 全连接层</span></span><br><span class="line">        <span class="variable language_">self</span>.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)            <span class="comment"># 全连接层</span></span><br><span class="line">        <span class="variable language_">self</span>.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">100</span>)            <span class="comment"># 输出层(CIFAR100有100类)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.pool(F.relu(<span class="variable language_">self</span>.conv1(x)))</span><br><span class="line">        x = <span class="variable language_">self</span>.pool(F.relu(<span class="variable language_">self</span>.conv2(x)))</span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>)               <span class="comment"># 展平</span></span><br><span class="line">        x = F.relu(<span class="variable language_">self</span>.fc1(x))</span><br><span class="line">        x = F.relu(<span class="variable language_">self</span>.fc2(x))</span><br><span class="line">        x = <span class="variable language_">self</span>.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">net = Net()</span><br></pre></td></tr></table></figure>

<h3 id="3-定义损失函数和优化器"><a href="#3-定义损失函数和优化器" class="headerlink" title="3. 定义损失函数和优化器"></a>3. 定义损失函数和优化器</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line">criterion = nn.CrossEntropyLoss()  <span class="comment"># 交叉熵损失</span></span><br><span class="line">optimizer = optim.SGD(             <span class="comment"># SGD优化器</span></span><br><span class="line">    net.parameters(), </span><br><span class="line">    lr=<span class="number">0.001</span>, </span><br><span class="line">    momentum=<span class="number">0.9</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<h3 id="4-训练网络"><a href="#4-训练网络" class="headerlink" title="4. 训练网络"></a>4. 训练网络</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):  <span class="comment"># 遍历数据集多次</span></span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(trainloader, <span class="number">0</span>):</span><br><span class="line">        inputs, labels = data</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 梯度清零</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 前向传播+反向传播+优化</span></span><br><span class="line">        outputs = net(inputs)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 打印统计信息</span></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">2000</span> == <span class="number">1999</span>:  <span class="comment"># 每2000个小批量打印一次</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;[%d, %5d] loss: %.3f&#x27;</span> % </span><br><span class="line">                 (epoch + <span class="number">1</span>, i + <span class="number">1</span>, running_loss / <span class="number">2000</span>))</span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存模型</span></span><br><span class="line">PATH = <span class="string">&#x27;./cifar_net.pth&#x27;</span></span><br><span class="line">torch.save(net.state_dict(), PATH)</span><br></pre></td></tr></table></figure>

<h3 id="5-测试网络性能"><a href="#5-测试网络性能" class="headerlink" title="5. 测试网络性能"></a>5. 测试网络性能</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测试整个数据集</span></span><br><span class="line">correct = <span class="number">0</span></span><br><span class="line">total = <span class="number">0</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> testloader:</span><br><span class="line">        images, labels = data</span><br><span class="line">        outputs = net(images)</span><br><span class="line">        _, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">        total += labels.size(<span class="number">0</span>)</span><br><span class="line">        correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy on 10000 test images: %d %%&#x27;</span> % (<span class="number">100</span> * correct / total))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 按类别测试准确率</span></span><br><span class="line">class_correct = <span class="built_in">list</span>(<span class="number">0.</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>))</span><br><span class="line">class_total = <span class="built_in">list</span>(<span class="number">0.</span> <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>))</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="keyword">for</span> data <span class="keyword">in</span> testloader:</span><br><span class="line">        images, labels = data</span><br><span class="line">        outputs = net(images)</span><br><span class="line">        _, predicted = torch.<span class="built_in">max</span>(outputs, <span class="number">1</span>)</span><br><span class="line">        c = (predicted == labels).squeeze()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">4</span>):</span><br><span class="line">            label = labels[i]</span><br><span class="line">            class_correct[label] += c[i].item()</span><br><span class="line">            class_total[label] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Accuracy of %5s : %2d %%&#x27;</span> % (</span><br><span class="line">        classes[i], <span class="number">100</span> * class_correct[i] / class_total[i]))</span><br></pre></td></tr></table></figure>

<h2 id="线性回归示例"><a href="#线性回归示例" class="headerlink" title="线性回归示例"></a>线性回归示例</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 准备数据</span></span><br><span class="line">x = torch.tensor([[<span class="number">1.0</span>], [<span class="number">2.0</span>], [<span class="number">3.0</span>]])</span><br><span class="line">y = torch.tensor([[<span class="number">3.0</span>], [<span class="number">6.0</span>], [<span class="number">9.0</span>]])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 定义模型</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">LinearModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(LinearModel, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.linear = nn.Linear(<span class="number">1</span>, <span class="number">1</span>)  <span class="comment"># 输入输出维度都是1</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.linear(x)</span><br><span class="line"></span><br><span class="line">model = LinearModel()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 定义损失和优化器</span></span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 训练循环</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line">    y_pred = model(x)          <span class="comment"># 前向传播</span></span><br><span class="line">    loss = criterion(y_pred, y) <span class="comment"># 计算损失</span></span><br><span class="line">    </span><br><span class="line">    optimizer.zero_grad()      <span class="comment"># 梯度清零</span></span><br><span class="line">    loss.backward()            <span class="comment"># 反向传播</span></span><br><span class="line">    optimizer.step()           <span class="comment"># 更新参数</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&#x27;Epoch <span class="subst">&#123;epoch&#125;</span>, Loss: <span class="subst">&#123;loss.item()&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印训练结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;w =&#x27;</span>, model.linear.weight.item())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;b =&#x27;</span>, model.linear.bias.item())</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/02/07/python_doc/pytorch/005-model%20training%20code/" data-id="cmbs36xvg0038ywsd4m9a27te" data-title="005-model training code" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Pytorch/" rel="tag">Pytorch</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-devops_doc/001-Docker基础复习" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/06/07/devops_doc/001-Docker%E5%9F%BA%E7%A1%80%E5%A4%8D%E4%B9%A0/" class="article-date">
  <time class="dt-published" datetime="2025-06-07T05:51:18.000Z" itemprop="datePublished">2025-06-07</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/DevOps/">DevOps</a>►<a class="article-category-link" href="/categories/DevOps/Docker/">Docker</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2025/06/07/devops_doc/001-Docker%E5%9F%BA%E7%A1%80%E5%A4%8D%E4%B9%A0/">001-Docker基础复习</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h3 id="一、基础概念类"><a href="#一、基础概念类" class="headerlink" title="一、基础概念类"></a><strong>一、基础概念类</strong></h3><ol>
<li><p><strong>Docker 是什么？与虚拟机有何本质区别？</strong></p>
<ul>
<li><strong>详解</strong>：Docker 是基于容器的轻量级虚拟化技术，通过共享宿主机内核实现进程级隔离。相比虚拟机（需完整操作系统，资源占用大），Docker 启动更快（秒级）、资源占用更低（镜像仅 MB 级），但隔离性较弱（依赖 Linux Namespace&#x2F;CGroups）。</li>
<li><strong>参考</strong>：<a target="_blank" rel="noopener" href="http://www.coreui.cn/news/150399.html">Docker 与虚拟机区别详解</a></li>
</ul>
</li>
<li><p><strong>Docker 三大核心组件及其关系？</strong></p>
<ul>
<li><strong>详解</strong>：<ul>
<li><strong>镜像（Image）</strong>：只读模板（如 <code>nginx:alpine</code>），含应用环境与代码。</li>
<li><strong>容器（Container）</strong>：镜像的运行实例，含可写层。</li>
<li><strong>仓库（Registry）</strong>：存储镜像的平台（如 Docker Hub）。</li>
<li><em>关系</em>：仓库 → 下载镜像 → 创建容器 。</li>
</ul>
</li>
<li><strong>参考</strong>：<a target="_blank" rel="noopener" href="https://www.imyhq.com/cloud-native/15760.html#comments">三大核心解析</a></li>
</ul>
</li>
<li><p><strong>为何使用 Docker？核心优势是什么？</strong></p>
<ul>
<li><strong>详解</strong>：<ul>
<li><strong>环境一致性</strong>：镜像打包应用+依赖，避免“开发-生产环境差异”。</li>
<li><strong>资源高效</strong>：容器共享内核，资源利用率比虚拟机高 70%+。</li>
<li><strong>快速部署</strong>：秒级启动，支持 CI&#x2F;CD 流水线。</li>
</ul>
</li>
<li><strong>参考</strong>：<a target="_blank" rel="noopener" href="http://www.coreui.cn/news/468052.html">Docker 核心优势分析</a></li>
</ul>
</li>
</ol>
<hr>
<h3 id="二、核心操作类"><a href="#二、核心操作类" class="headerlink" title="二、核心操作类"></a><strong>二、核心操作类</strong></h3><ol>
<li><p><strong>Dockerfile 中 <code>COPY</code> 与 <code>ADD</code> 指令的区别？</strong></p>
<ul>
<li><strong>详解</strong>：<ul>
<li><code>COPY</code>：仅复制文件&#x2F;目录到镜像（如 <code>COPY app.py /app</code>）。</li>
<li><code>ADD</code>：额外支持自动解压压缩包、从 URL 下载（不推荐，需手动清理缓存）。</li>
</ul>
</li>
<li><strong>参考</strong>：<a target="_blank" rel="noopener" href="https://www.miaokee.com/2845061.html">Dockerfile 指令详解</a></li>
</ul>
</li>
<li><p><strong>如何持久化容器数据？</strong></p>
<ul>
<li><strong>详解</strong>：<ul>
<li><strong>数据卷（Volume）</strong>：<code>docker run -v /host/path:/container/path</code>，数据存于宿主机，容器重启不丢失。</li>
<li><strong>数据卷容器</strong>：专用容器管理卷，供其他容器挂载 。</li>
</ul>
</li>
<li><strong>参考</strong>：<a target="_blank" rel="noopener" href="https://m.soso.com/web/sl?keyword=docker%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E8%B0%83%E4%BC%98&pid=sogou-mobb-e447193f2b83d789">数据存储管理</a></li>
</ul>
</li>
<li><p><strong>容器常见状态及转换命令？</strong></p>
<ul>
<li><strong>状态</strong>：<code>created</code> → <code>running</code> → <code>paused/exited</code> → <code>dead</code>。</li>
<li><strong>命令</strong>：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker start/stop/pause/unpause/rm &lt;container_id&gt;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
<hr>
<h3 id="三、网络与存储"><a href="#三、网络与存储" class="headerlink" title="三、网络与存储"></a><strong>三、网络与存储</strong></h3><ol>
<li><p><strong>Docker 网络模式有哪些？适用场景？</strong></p>
<table>
<thead>
<tr>
<th>模式</th>
<th>特点</th>
<th>场景</th>
</tr>
</thead>
<tbody><tr>
<td><code>bridge</code> (默认)</td>
<td>容器通过 <code>docker0</code> 网桥通信</td>
<td>多容器隔离环境（如 Web 应用）</td>
</tr>
<tr>
<td><code>host</code></td>
<td>共享宿主机网络栈</td>
<td>高性能场景（如负载测试）</td>
</tr>
<tr>
<td><code>overlay</code></td>
<td>跨主机容器通信（Swarm&#x2F;K8s）</td>
<td>集群部署</td>
</tr>
</tbody></table>
<ul>
<li><strong>参考</strong>：<a target="_blank" rel="noopener" href="http://www.coreui.cn/news/150399.html">网络模型详解</a></li>
</ul>
</li>
<li><p><strong>如何实现跨主机容器通信？</strong></p>
<ul>
<li><strong>详解</strong>：<ul>
<li><strong>Overlay 网络</strong>：基于 VXLAN 封装数据包，通过 UDP 传输（端口 4789）。</li>
<li><strong>Macvlan</strong>：为容器分配独立 MAC 地址，直连物理网络 。</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h3 id="四、容器编排与集群"><a href="#四、容器编排与集群" class="headerlink" title="四、容器编排与集群"></a><strong>四、容器编排与集群</strong></h3><ol>
<li><p><strong>Docker Compose vs Docker Swarm vs Kubernetes？</strong></p>
<ul>
<li><strong>对比</strong>：<table>
<thead>
<tr>
<th>工具</th>
<th>定位</th>
<th>适用场景</th>
</tr>
</thead>
<tbody><tr>
<td>Docker Compose</td>
<td>单机多容器编排</td>
<td>本地开发环境</td>
</tr>
<tr>
<td>Docker Swarm</td>
<td>轻量级集群管理</td>
<td>中小规模生产部署</td>
</tr>
<tr>
<td>Kubernetes</td>
<td>企业级容器编排</td>
<td>大规模微服务架构</td>
</tr>
</tbody></table>
</li>
<li><strong>参考</strong>：<a target="_blank" rel="noopener" href="https://m.soso.com/web/sl?keyword=docker%E9%9D%A2%E8%AF%95%E9%A2%98%E5%8F%8A%E8%B0%83%E4%BC%98&pid=sogou-mobb-e447193f2b83d789">编排工具对比</a></li>
</ul>
</li>
<li><p><strong>如何用 Docker Compose 定义服务依赖？</strong></p>
<ul>
<li><strong>示例</strong>：<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">web:</span></span><br><span class="line">    <span class="attr">depends_on:</span>  </span><br><span class="line">      <span class="bullet">-</span> <span class="string">db</span>  <span class="comment"># 确保 db 先启动</span></span><br><span class="line">  <span class="attr">db:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">postgres</span></span><br></pre></td></tr></table></figure></li>
<li><strong>参考</strong>：<a target="_blank" rel="noopener" href="https://www.miaokee.com/2845183.html">Compose 文件规范</a></li>
</ul>
</li>
</ol>
<hr>
<h3 id="五、实战调优与排错"><a href="#五、实战调优与排错" class="headerlink" title="五、实战调优与排错"></a><strong>五、实战调优与排错</strong></h3><ol>
<li><p><strong>如何优化 Docker 镜像体积？</strong></p>
<ul>
<li><strong>技巧</strong>：<ul>
<li>多阶段构建（移除编译依赖）。</li>
<li>使用 Alpine 等轻量基础镜像。</li>
<li>合并 RUN 指令减少镜像层 。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>查看容器日志的方法？</strong></p>
<ul>
<li><strong>命令</strong>：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker logs -f &lt;container_id&gt;  <span class="comment"># 实时日志</span></span><br><span class="line">docker inspect --format=<span class="string">&#x27;&#123;&#123;.LogPath&#125;&#125;&#x27;</span> &lt;container_id&gt;  <span class="comment"># 日志文件路径</span></span><br></pre></td></tr></table></figure></li>
<li><strong>参考</strong>：<a target="_blank" rel="noopener" href="https://www.ewbang.com/community/article/details/997896807.html">日志管理</a></li>
</ul>
</li>
</ol>
<hr>
<h3 id="六、高阶原理"><a href="#六、高阶原理" class="headerlink" title="六、高阶原理"></a><strong>六、高阶原理</strong></h3><ol>
<li><p><strong>Docker 如何实现资源隔离？</strong></p>
<ul>
<li><strong>技术栈</strong>：<ul>
<li><strong>Namespace</strong>：隔离进程、网络、文件系统等（如 <code>PID</code>、<code>NET</code>）。</li>
<li><strong>CGroups</strong>：限制 CPU&#x2F;内存用量（如 <code>docker run --cpus=2 --memory=1g</code>）。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>容器退出后数据会丢失吗？</strong></p>
<ul>
<li><strong>详解</strong>：默认停止的容器仍保留可写层（<code>docker ps -a</code> 可见），但删除容器后数据丢失，需用<strong>数据卷</strong>持久化 。</li>
</ul>
</li>
</ol>
<hr>
<h3 id="附：完整学习资源"><a href="#附：完整学习资源" class="headerlink" title="附：完整学习资源"></a><strong>附：完整学习资源</strong></h3><ul>
<li>📚 <strong>Docker 面试题大全</strong>：<a target="_blank" rel="noopener" href="https://www.miaokee.com/2845183.html">2024 最新题库</a></li>
<li>🔧 <strong>命令速查表</strong>：<a target="_blank" rel="noopener" href="https://www.uudwc.com/A/AEdx/">Docker 常用命令详解</a></li>
<li>⚙️ <strong>底层原理</strong>：<a target="_blank" rel="noopener" href="http://www.coreui.cn/news/150399.html">Namespace&#x2F;CGroups 解析</a></li>
</ul>
<hr>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/06/07/devops_doc/001-Docker%E5%9F%BA%E7%A1%80%E5%A4%8D%E4%B9%A0/" data-id="cmbs36xuv0007ywsd5prp0mic" data-title="001-Docker基础复习" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Docker/" rel="tag">Docker</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-javascript_doc/001-JavaScript-数据类型" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/06/09/javascript_doc/001-JavaScript-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/" class="article-date">
  <time class="dt-published" datetime="2025-06-09T05:44:37.000Z" itemprop="datePublished">2025-06-09</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/JavaScript/">JavaScript</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2025/06/09/javascript_doc/001-JavaScript-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/">001-JavaScript 数据类型</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">## JavaScript 数据类型</span></span><br><span class="line"></span><br><span class="line"><span class="section">### 两大分类</span></span><br><span class="line"><span class="bullet">1.</span> <span class="strong">**基本类型（Primitive Types）**</span>：</span><br><span class="line"><span class="bullet">-</span> <span class="code">`string`</span>：字符串</span><br><span class="line"><span class="bullet">-</span> <span class="code">`number`</span>：数字</span><br><span class="line"><span class="bullet">-</span> <span class="code">`boolean`</span>：布尔值</span><br><span class="line"><span class="bullet">-</span> <span class="code">`null`</span>：空值</span><br><span class="line"><span class="bullet">-</span> <span class="code">`undefined`</span>：未定义</span><br><span class="line"><span class="bullet">-</span> <span class="code">`symbol`</span>（ES6新增）：符号，表示唯一值</span><br><span class="line"><span class="bullet">-</span> <span class="code">`bigint`</span>（ES2020新增）：大整数，表示任意大的整数</span><br><span class="line"></span><br><span class="line"><span class="bullet">2.</span> <span class="strong">**引用类型（Reference Types）**</span>：</span><br><span class="line"><span class="bullet">-</span> <span class="code">`Object`</span>：对象</span><br><span class="line"><span class="bullet">-</span> 包括：<span class="code">`Array`</span>, <span class="code">`Function`</span>, <span class="code">`Date`</span>, <span class="code">`RegExp`</span>, <span class="code">`Map`</span>, <span class="code">`Set`</span>, <span class="code">`WeakMap`</span>, <span class="code">`WeakSet`</span>等。</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line"><span class="section">## 基本类型 vs 引用类型的核心区别</span></span><br><span class="line"></span><br><span class="line">| <span class="strong">**特性**</span>         | <span class="strong">**基本类型**</span>                              | <span class="strong">**引用类型**</span>                              |</span><br><span class="line">|------------------|------------------------------------------|------------------------------------------|</span><br><span class="line">| 存储方式         | 栈内存（直接存储值）                     | 堆内存（存储地址，栈中存指针）           |</span><br><span class="line">| 赋值行为         | 复制值（新旧变量互不影响）               | 复制指针（指向同一内存对象）             |</span><br><span class="line">| 比较方式         | 值比较（<span class="code">`&#x27;a&#x27; === &#x27;a&#x27;`</span> → <span class="code">`true`</span>）         | 引用比较（<span class="code">`&#123;&#125; === &#123;&#125;`</span> → <span class="code">`false`</span>）        |</span><br><span class="line">| 函数传参         | 传递值的副本                              | 传递指针副本（内部修改影响外部对象）     |</span><br><span class="line">| 动态属性         | 不可添加属性                             | 可动态添加/删除属性                      |</span><br><span class="line">| 内存管理         | 变量销毁时自动回收                       | 需垃圾回收机制处理                       |</span><br><span class="line"></span><br><span class="line">复习一下数据结构：</span><br><span class="line">1.栈（Stack）</span><br><span class="line">  逻辑结构：一种线性结构，遵循<span class="strong">**后进先出（LIFO）**</span>原则，仅允许在表的一端（栈顶）进行插入（push）和删除（pop）操作。</span><br><span class="line">  物理实现：通常通过数组或链表实现，数据连续存储，操作仅涉及栈顶元素。</span><br><span class="line">  典型操作：</span><br><span class="line"><span class="code">    push：将元素压入栈顶。</span></span><br><span class="line"><span class="code">    pop：弹出栈顶元素。</span></span><br><span class="line"><span class="code">    peek：查看栈顶元素（不弹出）。</span></span><br><span class="line"><span class="code">2.堆（Heap）</span></span><br><span class="line"><span class="code">  逻辑结构：一种树形结构，通常为完全二叉树，满足堆性质（父节点的值大于或等于子节点的值称为最大堆，反之为最小堆）。</span></span><br><span class="line"><span class="code">  物理实现：通过数组实现，逻辑上模拟树结构，物理上连续存储。</span></span><br><span class="line"><span class="code">  典型操作：</span></span><br><span class="line"><span class="code">    insert：插入元素并保持堆性质。</span></span><br><span class="line"><span class="code">    extract：移除根节点（最大或最小值）。</span></span><br><span class="line"><span class="code">    heapify：调整节点位置以维护堆性质。</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="section">### 示例说明</span></span><br><span class="line"><span class="code">```javascript</span></span><br><span class="line"><span class="code">// 基本类型 - 值复制</span></span><br><span class="line"><span class="code">let num1 = 10;</span></span><br><span class="line"><span class="code">let num2 = num1;  // 值复制</span></span><br><span class="line"><span class="code">num2 = 20;</span></span><br><span class="line"><span class="code">console.log(num1); // 10（不受影响）</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code">// 引用类型 - 指针复制</span></span><br><span class="line"><span class="code">let obj1 = &#123; count: 10 &#125;;</span></span><br><span class="line"><span class="code">let obj2 = obj1;   // 指针复制</span></span><br><span class="line"><span class="code">obj2.count = 20;</span></span><br><span class="line"><span class="code">console.log(obj1.count); // 20（同步修改）</span></span><br></pre></td></tr></table></figure>

<hr>
<h2 id="Symbol-详解"><a href="#Symbol-详解" class="headerlink" title="Symbol 详解"></a>Symbol 详解</h2><p><strong>作用</strong>：创建唯一的、不可变的值，常用作对象属性的键（避免命名冲突）。<br><strong>特性</strong>：</p>
<ul>
<li>通过 <code>Symbol([description])</code> 创建</li>
<li>即使描述相同，Symbol 值也不同：<code>Symbol(&#39;id&#39;) !== Symbol(&#39;id&#39;)</code></li>
<li>不可枚举（<code>for...in</code> 跳过），需用 <code>Object.getOwnPropertySymbols()</code> 获取<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> sym1 = <span class="title class_">Symbol</span>(<span class="string">&#x27;id&#x27;</span>);</span><br><span class="line"><span class="keyword">const</span> sym2 = <span class="title class_">Symbol</span>(<span class="string">&#x27;id&#x27;</span>);</span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(sym1 === sym2); <span class="comment">// false（唯一性）</span></span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="应用场景："><a href="#应用场景：" class="headerlink" title="应用场景："></a>应用场景：</h4><ol>
<li><p><strong>唯一对象属性键</strong><br>避免第三方库属性名冲突：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> user = &#123;</span><br><span class="line">  <span class="attr">name</span>: <span class="string">&quot;Alice&quot;</span>,</span><br><span class="line">  [<span class="title class_">Symbol</span>(<span class="string">&#x27;id&#x27;</span>)]: <span class="number">123</span> <span class="comment">// 隐藏属性</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></li>
<li><p><strong>模拟私有属性</strong><br>（需配合 <code>Object.defineProperty</code> 或闭包实现真正私有）：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> _password = <span class="title class_">Symbol</span>(<span class="string">&#x27;password&#x27;</span>);</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">User</span> &#123;</span><br><span class="line">  <span class="title function_">constructor</span>(<span class="params">password</span>) &#123;</span><br><span class="line">    <span class="variable language_">this</span>[_password] = password;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p><strong>全局 Symbol 注册表</strong><br>跨模块共享 Symbol：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// module1.js</span></span><br><span class="line"><span class="keyword">const</span> id = <span class="title class_">Symbol</span>.<span class="title function_">for</span>(<span class="string">&#x27;global_id&#x27;</span>);</span><br><span class="line"><span class="comment">// module2.js</span></span><br><span class="line"><span class="keyword">const</span> sameId = <span class="title class_">Symbol</span>.<span class="title function_">for</span>(<span class="string">&#x27;global_id&#x27;</span>);</span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(id === sameId); <span class="comment">// true</span></span><br></pre></td></tr></table></figure></li>
<li><p><strong>内置 Symbol 值</strong><br>定制对象行为（如迭代器）：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> obj = &#123;</span><br><span class="line">  [<span class="title class_">Symbol</span>.<span class="property">iterator</span>]: <span class="keyword">function</span>* () &#123;</span><br><span class="line">    <span class="keyword">yield</span> <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">yield</span> <span class="number">2</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>([...obj]); <span class="comment">// [1, 2]</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><table>
<thead>
<tr>
<th><strong>场景</strong></th>
<th><strong>说明</strong></th>
<th><strong>示例</strong></th>
</tr>
</thead>
<tbody><tr>
<td>唯一对象属性键</td>
<td>由于Symbol值是唯一的，因此可以用来作为对象属性的键，避免属性名冲突</td>
<td><code>const obj = &#123; [Symbol(&#39;id&#39;)]: 123 &#125;; </code></td>
</tr>
<tr>
<td>模拟私有属性</td>
<td>配合闭包实现伪私有属性（虽然ES6的类并没有真正的私有属性，但使用Symbol可以在一定程度上模拟私有属性，因为外部无法直接访问Symbol属性）</td>
<td><code>const _key = Symbol(); class Safe &#123; constructor(k) &#123; this[_key] = k; &#125; &#125; </code></td>
</tr>
<tr>
<td>全局Symbol注册表</td>
<td>跨模块&#x2F;文件共享Symbol</td>
<td><code>//module1.js Symbol.for(&#39;global&#39;); //module2.js Symbol.for(&#39;global&#39;); </code></td>
</tr>
<tr>
<td>内置Symbol行为定制</td>
<td>实现迭代协议等特殊行为（ES6提供了一些内置的Symbol值，用于改变语言内部行为，如<code>Symbol.iterator</code>（定义迭代器）、<code>Symbol.toStringTag</code>）</td>
<td><code>const iterable = &#123; [Symbol.iterator]: function*() &#123; yield 1; &#125; &#125;; </code></td>
</tr>
<tr>
<td>定义常量</td>
<td>用于定义一组常量，保证这组常量的值都是不相等的。</td>
<td><code>const LOG_LEVEL = &#123;DEBUG: Symbol(&#39;debug&#39;),INFO: Symbol(&#39;info&#39;),ERROR: Symbol(&#39;error&#39;)&#125;;</code></td>
</tr>
</tbody></table>
<hr>
<h2 id="BigInt-详解"><a href="#BigInt-详解" class="headerlink" title="BigInt 详解"></a>BigInt 详解</h2><h3 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h3><p>Bi<strong>作用</strong>：表示任意精度的整数，解决 <code>Number</code> 类型无法安全表示的大整数问题（<code>Number.MAX_SAFE_INTEGER = 2^53 - 1</code>）。<br><strong>特性</strong>：</p>
<ul>
<li>字面量加 <code>n</code> 后缀：<code>12345678901234567890n</code></li>
<li>通过 <code>BigInt()</code> 函数转换：<code>BigInt(&quot;9007199254740993&quot;)</code></li>
<li>不能与 <code>Number</code> 直接运算（需显式转换）</li>
</ul>
<h4 id="应用场景：-1"><a href="#应用场景：-1" class="headerlink" title="应用场景："></a>应用场景：</h4><ol>
<li><p><strong>大整数运算</strong><br>金融、科学计算等需要高精度的场景：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> big1 = <span class="number">9007199254740993n</span>;</span><br><span class="line"><span class="keyword">const</span> big2 = <span class="number">1n</span>;</span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(big1 + big2); <span class="comment">// 9007199254740994n</span></span><br></pre></td></tr></table></figure></li>
<li><p><strong>大 ID 处理</strong><br>数据库返回的 64 位 ID（如 Snowflake 算法生成的 ID）：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> id = <span class="title class_">BigInt</span>(<span class="string">&quot;12345678901234567890&quot;</span>); <span class="comment">// 超出 Number 安全范围</span></span><br></pre></td></tr></table></figure></li>
<li><p><strong>高精度时间戳</strong><br>纳秒级时间戳运算：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> start = process.<span class="property">hrtime</span>.<span class="title function_">bigint</span>(); <span class="comment">// Node.js</span></span><br><span class="line"><span class="comment">// 执行操作...</span></span><br><span class="line"><span class="keyword">const</span> end = process.<span class="property">hrtime</span>.<span class="title function_">bigint</span>();</span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="string">`耗时: <span class="subst">$&#123;(end - start) / <span class="number">1000000n</span>&#125;</span> 毫秒`</span>);</span><br></pre></td></tr></table></figure></li>
<li><p><strong>大数加密&#x2F;哈希</strong><br>密码学中的大整数运算：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> prime = <span class="title class_">BigInt</span>(<span class="string">&quot;0xFFFFFFFFFFFFFFFFC90FDAA...&quot;</span>);</span><br></pre></td></tr></table></figure></li>
</ol>
<h4 id="注意事项："><a href="#注意事项：" class="headerlink" title="注意事项："></a>注意事项：</h4><ul>
<li>不支持 <code>Math</code> 对象的方法</li>
<li>与 <code>Number</code> 比较时类型不同（<code>1n === 1</code> → <code>false</code>）</li>
<li><strong>JSON 序列化</strong>需自定义处理（默认抛出错误）</li>
</ul>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 类型转换</span></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="number">1n</span> == <span class="number">1</span>);   <span class="comment">// true（值相等）</span></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="number">1n</span> === <span class="number">1</span>);  <span class="comment">// false（类型不同）</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 运算限制</span></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(<span class="title class_">Math</span>.<span class="title function_">sqrt</span>(<span class="number">16n</span>)); <span class="comment">// TypeError（不支持Math方法）</span></span><br></pre></td></tr></table></figure>

<hr>
<h2 id="总结对比"><a href="#总结对比" class="headerlink" title="总结对比"></a>总结对比</h2><table>
<thead>
<tr>
<th><strong>类型</strong></th>
<th><strong>核心特性</strong></th>
<th><strong>典型应用场景</strong></th>
</tr>
</thead>
<tbody><tr>
<td><code>Symbol</code></td>
<td>唯一性、不可枚举、避免冲突</td>
<td>对象元编程、私有属性模拟、库开发</td>
</tr>
<tr>
<td><code>BigInt</code></td>
<td>任意精度、突破<code>Number</code>安全限制</td>
<td>大整数ID、金融计算、高精度时间处理</td>
</tr>
</tbody></table>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/06/09/javascript_doc/001-JavaScript-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/" data-id="cmbs36xuw000bywsd1nryhry6" data-title="001-JavaScript 数据类型" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Javascript/" rel="tag">Javascript</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-javascript_doc/002-JavaScript-类型判断方法详解" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/06/09/javascript_doc/002-JavaScript-%E7%B1%BB%E5%9E%8B%E5%88%A4%E6%96%AD%E6%96%B9%E6%B3%95%E8%AF%A6%E8%A7%A3/" class="article-date">
  <time class="dt-published" datetime="2025-06-09T05:44:56.000Z" itemprop="datePublished">2025-06-09</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/JavaScript/">JavaScript</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2025/06/09/javascript_doc/002-JavaScript-%E7%B1%BB%E5%9E%8B%E5%88%A4%E6%96%AD%E6%96%B9%E6%B3%95%E8%AF%A6%E8%A7%A3/">002-JavaScript 类型判断方法详解</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">## JavaScript 类型判断方法详解</span></span><br><span class="line"></span><br><span class="line"><span class="section">### 1. 判断数据类型的常用方法</span></span><br><span class="line">| <span class="strong">**方法**</span>         | <span class="strong">**说明**</span>                                                                 | <span class="strong">**示例**</span>                                 |</span><br><span class="line">|------------------|-------------------------------------------------------------------------|-----------------------------------------|</span><br><span class="line">| <span class="code">`typeof`</span>         | 返回基本类型字符串，对引用类型（除函数）返回 <span class="code">`&quot;object&quot;`</span>                  | <span class="code">`typeof &quot;str&quot;`</span> → <span class="code">`&quot;string&quot;`</span>             |</span><br><span class="line">| <span class="code">`instanceof`</span>     | 检测构造函数的原型是否在对象原型链上（用于引用类型）                    | <span class="code">`[] instanceof Array`</span> → <span class="code">`true`</span>          |</span><br><span class="line">| <span class="code">`Object.prototype.toString.call()`</span> | 最准确的类型判断方法，返回 <span class="code">`[object Type]`</span> 格式字符串 | <span class="code">`toString.call(null)`</span> → <span class="code">`[object Null]`</span> |</span><br><span class="line">| <span class="code">`Array.isArray()`</span> | ES5 新增的数组检测方法                                                  | <span class="code">`Array.isArray([])`</span> → <span class="code">`true`</span>            |</span><br><span class="line">| <span class="code">`===`</span>            | 特殊值直接比较（<span class="code">`null`</span>/<span class="code">`undefined`</span>）                                    | <span class="code">`value === null`</span>                        |</span><br><span class="line"></span><br><span class="line"><span class="section">### 2. `instanceof` 原理</span></span><br><span class="line"><span class="strong">**实现机制**</span>：  </span><br><span class="line">沿着对象的原型链向上查找，检查构造函数的 <span class="code">`prototype`</span> 属性是否出现在原型链中</span><br><span class="line"></span><br><span class="line"><span class="code">```javascript</span></span><br><span class="line"><span class="code">function myInstanceof(obj, constructor) &#123;</span></span><br><span class="line"><span class="code">  // 获取对象的原型</span></span><br><span class="line"><span class="code">  let proto = Object.getPrototypeOf(obj);</span></span><br><span class="line"><span class="code">  </span></span><br><span class="line"><span class="code">  while (proto) &#123;</span></span><br><span class="line"><span class="code">    // 找到原型匹配</span></span><br><span class="line"><span class="code">    if (proto === constructor.prototype) return true;</span></span><br><span class="line"><span class="code">    // 继续向上查找</span></span><br><span class="line"><span class="code">    proto = Object.getPrototypeOf(proto);</span></span><br><span class="line"><span class="code">  &#125;</span></span><br><span class="line"><span class="code">  return false;</span></span><br><span class="line"><span class="code">&#125;</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code">// 测试</span></span><br><span class="line"><span class="code">console.log(myInstanceof([], Array));   // true</span></span><br><span class="line"><span class="code">console.log(myInstanceof(&#123;&#125;, Object));  // true</span></span><br><span class="line"><span class="code">console.log(myInstanceof([], Object));  // true（Array继承自Object）</span></span><br></pre></td></tr></table></figure>

<p><strong>注意事项</strong>：</p>
<ul>
<li>对基本类型无效：<code>1 instanceof Number</code> → <code>false</code></li>
<li>跨框架对象检测可能失效（不同执行环境有不同原型）</li>
<li>修改 <code>prototype</code> 可能导致意外行为</li>
</ul>
<h3 id="3-判断空对象的-4-种方法"><a href="#3-判断空对象的-4-种方法" class="headerlink" title="3. 判断空对象的 4 种方法"></a>3. 判断空对象的 4 种方法</h3><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> obj = &#123;&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 方法1：Object.keys（推荐）</span></span><br><span class="line"><span class="title class_">Object</span>.<span class="title function_">keys</span>(obj).<span class="property">length</span> === <span class="number">0</span>;  <span class="comment">// true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 方法2：JSON.stringify</span></span><br><span class="line"><span class="title class_">JSON</span>.<span class="title function_">stringify</span>(obj) === <span class="string">&#x27;&#123;&#125;&#x27;</span>;   <span class="comment">// true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 方法3：for...in 遍历</span></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">isEmpty</span>(<span class="params">obj</span>) &#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">let</span> key <span class="keyword">in</span> obj) &#123;</span><br><span class="line">    <span class="keyword">if</span> (obj.<span class="title function_">hasOwnProperty</span>(key)) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 方法4：Object.getOwnPropertyNames</span></span><br><span class="line"><span class="title class_">Object</span>.<span class="title function_">getOwnPropertyNames</span>(obj).<span class="property">length</span> === <span class="number">0</span>; <span class="comment">// true</span></span><br></pre></td></tr></table></figure>

<p><strong>特殊案例处理</strong>：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Symbol 属性需单独检测</span></span><br><span class="line"><span class="keyword">const</span> symObj = &#123; [<span class="title class_">Symbol</span>(<span class="string">&#x27;key&#x27;</span>)]: <span class="string">&#x27;value&#x27;</span> &#125;;</span><br><span class="line"><span class="title class_">Object</span>.<span class="title function_">getOwnPropertySymbols</span>(symObj).<span class="property">length</span> === <span class="number">0</span>; <span class="comment">// false</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 不可枚举属性</span></span><br><span class="line"><span class="keyword">const</span> nonEnum = <span class="title class_">Object</span>.<span class="title function_">create</span>(&#123;&#125;, &#123;</span><br><span class="line">  <span class="attr">hidden</span>: &#123; <span class="attr">value</span>: <span class="string">&#x27;secret&#x27;</span>, <span class="attr">enumerable</span>: <span class="literal">false</span> &#125;</span><br><span class="line">&#125;);</span><br><span class="line"><span class="title class_">Object</span>.<span class="title function_">keys</span>(nonEnum).<span class="property">length</span> === <span class="number">0</span>; <span class="comment">// true（需注意）</span></span><br></pre></td></tr></table></figure>

<h3 id="4-typeof-null-的特殊性"><a href="#4-typeof-null-的特殊性" class="headerlink" title="4. typeof null 的特殊性"></a>4. <code>typeof null</code> 的特殊性</h3><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typeof</span> <span class="literal">null</span>; <span class="comment">// &quot;object&quot;（历史遗留问题）</span></span><br></pre></td></tr></table></figure>

<p><strong>原因</strong>：<br>JavaScript 早期设计时用二进制前三位标识类型：</p>
<ul>
<li><code>000</code>：对象类型</li>
<li><code>1</code>：整型</li>
<li><code>010</code>：双精度浮点型</li>
<li><code>100</code>：字符串</li>
<li><code>110</code>：布尔型<br><code>null</code> 的二进制全为 <code>0</code>，被错误识别为对象类型</li>
</ul>
<p><strong>正确检测 null</strong>：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="title function_">isNull</span> = (<span class="params">value</span>) =&gt; value === <span class="literal">null</span>;  <span class="comment">// 直接全等比较</span></span><br></pre></td></tr></table></figure>

<h3 id="5-typeof-NaN-的特殊性"><a href="#5-typeof-NaN-的特殊性" class="headerlink" title="5. typeof NaN 的特殊性"></a>5. <code>typeof NaN</code> 的特殊性</h3><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typeof</span> <span class="title class_">NaN</span>; <span class="comment">// &quot;number&quot;（符合IEEE 754标准）</span></span><br></pre></td></tr></table></figure>

<p><strong>NaN 的特性</strong>：</p>
<ul>
<li>全称：Not-A-Number（非数字）</li>
<li>是特殊的 Number 类型值</li>
<li>由无效数学运算产生：<code>0/0</code>, <code>Math.sqrt(-1)</code></li>
<li>不等于任何值（包括自身）：<code>NaN === NaN</code> → <code>false</code></li>
</ul>
<p><strong>检测 NaN 的方法</strong>：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// ES6 推荐方法</span></span><br><span class="line"><span class="title class_">Number</span>.<span class="built_in">isNaN</span>(<span class="title class_">NaN</span>);  <span class="comment">// true</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 兼容旧环境方法</span></span><br><span class="line"><span class="keyword">function</span> <span class="title function_">isNaN</span>(<span class="params">value</span>) &#123;</span><br><span class="line">  <span class="keyword">return</span> value !== value;  <span class="comment">// NaN是唯一不自等的值</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 注意全局isNaN的缺陷（会先尝试类型转换）</span></span><br><span class="line"><span class="built_in">isNaN</span>(<span class="string">&quot;hello&quot;</span>);     <span class="comment">// true（字符串被转成NaN）</span></span><br><span class="line"><span class="title class_">Number</span>.<span class="built_in">isNaN</span>(<span class="string">&quot;hello&quot;</span>); <span class="comment">// false（严格检测）</span></span><br></pre></td></tr></table></figure>

<h3 id="类型判断总结表"><a href="#类型判断总结表" class="headerlink" title="类型判断总结表"></a>类型判断总结表</h3><table>
<thead>
<tr>
<th><strong>表达式</strong></th>
<th><strong>结果</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td><code>typeof &quot;hello&quot;</code></td>
<td><code>&quot;string&quot;</code></td>
<td>基本类型准确检测</td>
</tr>
<tr>
<td><code>typeof null</code></td>
<td><code>&quot;object&quot;</code></td>
<td>历史遗留问题</td>
</tr>
<tr>
<td><code>typeof NaN</code></td>
<td><code>&quot;number&quot;</code></td>
<td>IEEE 754 标准定义</td>
</tr>
<tr>
<td><code>typeof function() &#123;&#125;</code></td>
<td><code>&quot;function&quot;</code></td>
<td>函数的特殊处理</td>
</tr>
<tr>
<td><code>[] instanceof Array</code></td>
<td><code>true</code></td>
<td>原型链检测</td>
</tr>
<tr>
<td><code>Object.prototype.toString.call(&#123;&#125;)</code></td>
<td><code>&quot;[object Object]&quot;</code></td>
<td>最可靠的类型判断</td>
</tr>
</tbody></table>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/06/09/javascript_doc/002-JavaScript-%E7%B1%BB%E5%9E%8B%E5%88%A4%E6%96%AD%E6%96%B9%E6%B3%95%E8%AF%A6%E8%A7%A3/" data-id="cmbs36xux000cywsdad5z8ek8" data-title="002-JavaScript 类型判断方法详解" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Javascript/" rel="tag">Javascript</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-javascript_doc/003-var-let-const-全面对比" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/06/09/javascript_doc/003-var-let-const-%E5%85%A8%E9%9D%A2%E5%AF%B9%E6%AF%94/" class="article-date">
  <time class="dt-published" datetime="2025-06-09T05:45:20.000Z" itemprop="datePublished">2025-06-09</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/JavaScript/">JavaScript</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2025/06/09/javascript_doc/003-var-let-const-%E5%85%A8%E9%9D%A2%E5%AF%B9%E6%AF%94/">003-var-let-const 全面对比</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">## var / let / const 全面对比</span></span><br><span class="line"></span><br><span class="line"><span class="section">### 核心区别总结</span></span><br><span class="line">| <span class="strong">**特性**</span>         | <span class="code">`var`</span>                  | <span class="code">`let`</span>                  | <span class="code">`const`</span>                |</span><br><span class="line">|------------------|------------------------|------------------------|------------------------|</span><br><span class="line">| <span class="strong">**作用域**</span>       | 函数作用域             | 块级作用域             | 块级作用域             |</span><br><span class="line">| <span class="strong">**变量提升**</span>     | 提升并初始化<span class="code">`undefined`</span>| 提升但不初始化（TDZ）  | 提升但不初始化（TDZ）  |</span><br><span class="line">| <span class="strong">**重复声明**</span>     | ✅ 允许                 | ❌ 禁止                 | ❌ 禁止                 |</span><br><span class="line">| <span class="strong">**全局绑定**</span>     | 成为<span class="code">`window`</span>属性       | 不成为<span class="code">`window`</span>属性     | 不成为<span class="code">`window`</span>属性     |</span><br><span class="line">| <span class="strong">**初始值**</span>       | 可不初始化             | 可不初始化             | ❌ 必须初始化          |</span><br><span class="line">| <span class="strong">**循环中的表现**</span> | 每次循环共享同一变量   | 每次迭代创建新绑定     | 每次迭代创建新绑定     |</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line"><span class="section">### 关键概念详解</span></span><br><span class="line"></span><br><span class="line"><span class="section">#### 1. 块级作用域（Block Scope）</span></span><br><span class="line"><span class="code">`let`</span>和<span class="code">`const`</span>声明的变量只在代码块<span class="code">`&#123;&#125;`</span>内有效：</span><br><span class="line"><span class="code">```javascript</span></span><br><span class="line"><span class="code">&#123;</span></span><br><span class="line"><span class="code">  var a = 1;</span></span><br><span class="line"><span class="code">  let b = 2;</span></span><br><span class="line"><span class="code">  const c = 3;</span></span><br><span class="line"><span class="code">&#125;</span></span><br><span class="line"><span class="code">console.log(a); // 1（var穿透块作用域）</span></span><br><span class="line"><span class="code">console.log(b); // ReferenceError</span></span><br><span class="line"><span class="code">console.log(c); // ReferenceError</span></span><br></pre></td></tr></table></figure>

<p><strong>典型应用</strong>：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 解决循环变量泄露</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">let</span> i = <span class="number">0</span>; i &lt; <span class="number">3</span>; i++) &#123;</span><br><span class="line">  <span class="built_in">setTimeout</span>(<span class="function">() =&gt;</span> <span class="variable language_">console</span>.<span class="title function_">log</span>(i)); <span class="comment">// 0,1,2（正确）</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">var</span> j = <span class="number">0</span>; j &lt; <span class="number">3</span>; j++) &#123;</span><br><span class="line">  <span class="built_in">setTimeout</span>(<span class="function">() =&gt;</span> <span class="variable language_">console</span>.<span class="title function_">log</span>(j)); <span class="comment">// 3,3,3（泄露到全局）</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="2-暂时性死区（TDZ-Temporal-Dead-Zone）"><a href="#2-暂时性死区（TDZ-Temporal-Dead-Zone）" class="headerlink" title="2. 暂时性死区（TDZ - Temporal Dead Zone）"></a>2. 暂时性死区（TDZ - Temporal Dead Zone）</h4><p>在声明前访问<code>let/const</code>变量会触发错误（而<code>var</code>返回<code>undefined</code>）：</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(a); <span class="comment">// undefined（变量提升）</span></span><br><span class="line"><span class="keyword">var</span> a = <span class="number">10</span>;</span><br><span class="line"></span><br><span class="line"><span class="variable language_">console</span>.<span class="title function_">log</span>(b); <span class="comment">// ReferenceError（TDZ区域）</span></span><br><span class="line"><span class="keyword">let</span> b = <span class="number">20</span>;</span><br></pre></td></tr></table></figure>

<p><strong>TDZ 本质</strong>：<br>从进入作用域到变量声明之间的区域，禁止访问变量</p>
<h4 id="3-const-的特殊行为"><a href="#3-const-的特殊行为" class="headerlink" title="3. const 的特殊行为"></a>3. const 的特殊行为</h4><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> a = &#123;&#125;;</span><br><span class="line">a.<span class="property">x</span> = <span class="number">1</span>; <span class="comment">// ✅ 允许（修改对象内部属性）</span></span><br><span class="line">a = &#123;&#125;;  <span class="comment">// ❌ TypeError（禁止重新赋值）</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> b = <span class="title class_">Object</span>.<span class="title function_">freeze</span>(&#123;&#125;);</span><br><span class="line">b.<span class="property">x</span> = <span class="number">1</span>; <span class="comment">// ❌ 静默失败（严格模式报错）</span></span><br></pre></td></tr></table></figure>

<p><strong>const 本质</strong>：</p>
<ul>
<li>保证变量指向的内存地址不变（对于对象是堆地址，对于基本类型是栈值）</li>
<li>对象属性修改不受限制（除非使用<code>Object.freeze</code>）</li>
</ul>
<hr>
<h3 id="最佳实践指南"><a href="#最佳实践指南" class="headerlink" title="最佳实践指南"></a>最佳实践指南</h3><ol>
<li><p>**默认使用 <code>const</code>**<br>除非需要重新赋值，否则优先用<code>const</code>（减少意外修改）</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="variable constant_">API_URL</span> = <span class="string">&quot;https://api.example.com&quot;</span>;</span><br><span class="line"><span class="keyword">const</span> config = &#123; <span class="attr">timeout</span>: <span class="number">5000</span> &#125;;</span><br></pre></td></tr></table></figure>
</li>
<li><p>**需要重新赋值时用 <code>let</code>**<br>替代<code>var</code>的所有场景</p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> count = <span class="number">0</span>;</span><br><span class="line">count = <span class="title function_">processItems</span>(items);</span><br></pre></td></tr></table></figure>
</li>
<li><p>**避免使用 <code>var</code>**<br>除特殊兼容场景外不应使用</p>
</li>
<li><p><strong>const 对象保护技巧</strong></p>
<figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 深度冻结对象</span></span><br><span class="line"><span class="keyword">const</span> <span class="title function_">deepFreeze</span> = obj =&gt; &#123;</span><br><span class="line">  <span class="title class_">Object</span>.<span class="title function_">freeze</span>(obj);</span><br><span class="line">  <span class="title class_">Object</span>.<span class="title function_">keys</span>(obj).<span class="title function_">forEach</span>(<span class="function"><span class="params">key</span> =&gt;</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">typeof</span> obj[key] === <span class="string">&#x27;object&#x27;</span>) <span class="title function_">deepFreeze</span>(obj[key]);</span><br><span class="line">  &#125;);</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> safeObj = <span class="title function_">deepFreeze</span>(&#123; <span class="attr">nested</span>: &#123; <span class="attr">value</span>: <span class="number">1</span> &#125; &#125;);</span><br><span class="line">safeObj.<span class="property">nested</span>.<span class="property">value</span> = <span class="number">2</span>; <span class="comment">// ❌ 严格模式报错</span></span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="常见误区"><a href="#常见误区" class="headerlink" title="常见误区"></a>常见误区</h3><figure class="highlight javascript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 误区1：const不能修改对象</span></span><br><span class="line"><span class="keyword">const</span> user = &#123; <span class="attr">name</span>: <span class="string">&quot;Alice&quot;</span> &#125;;</span><br><span class="line">user.<span class="property">name</span> = <span class="string">&quot;Bob&quot;</span>; <span class="comment">// ✅ 允许</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 误区2：循环中的const</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">const</span> i = <span class="number">0</span>; i &lt; <span class="number">3</span>; i++) &#123; <span class="comment">// ❌ i++导致重新赋值报错</span></span><br><span class="line">  <span class="variable language_">console</span>.<span class="title function_">log</span>(i);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 正确用法</span></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">const</span> item <span class="keyword">of</span> [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]) &#123; <span class="comment">// ✅ 每次迭代创建新绑定</span></span><br><span class="line">  <span class="variable language_">console</span>.<span class="title function_">log</span>(item);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="浏览器兼容性"><a href="#浏览器兼容性" class="headerlink" title="浏览器兼容性"></a>浏览器兼容性</h3><ul>
<li><code>let/const</code>：ES6+（现代浏览器全支持，IE11部分支持）</li>
<li>旧环境需通过Babel转译为ES5</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>


      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/06/09/javascript_doc/003-var-let-const-%E5%85%A8%E9%9D%A2%E5%AF%B9%E6%AF%94/" data-id="cmbs36xux000gywsdfckqgnrv" data-title="003-var-let-const 全面对比" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Javascript/" rel="tag">Javascript</a></li></ul>

    </footer>
  </div>
  
</article>



  


  <nav id="page-nav">
    
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/CNBC/">CNBC</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/CSS/">CSS</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/DevOps/">DevOps</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/DevOps/Docker/">Docker</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/DevOps/Openshift/">Openshift</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/JavaScript/">JavaScript</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Principles/">Principles</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Pytorch/">Pytorch</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNBC-Finance/" rel="tag">CNBC Finance</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CSS/" rel="tag">CSS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Docker/" rel="tag">Docker</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Javascript/" rel="tag">Javascript</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Openshift/" rel="tag">Openshift</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Principles/" rel="tag">Principles</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Pytorch/" rel="tag">Pytorch</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/CNBC-Finance/" style="font-size: 10px;">CNBC Finance</a> <a href="/tags/CSS/" style="font-size: 10px;">CSS</a> <a href="/tags/Docker/" style="font-size: 10px;">Docker</a> <a href="/tags/Javascript/" style="font-size: 20px;">Javascript</a> <a href="/tags/Openshift/" style="font-size: 10px;">Openshift</a> <a href="/tags/Principles/" style="font-size: 10px;">Principles</a> <a href="/tags/Pytorch/" style="font-size: 15px;">Pytorch</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/06/">June 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/02/">February 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/01/">January 2021</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2025/06/11/data_structiure_and_algorithms_doc/algorithms_solution_doc/013-%E5%88%86%E5%89%B2%E5%9B%9E%E6%96%87%E4%B8%B2%EF%BC%88%E5%9B%9E%E6%BA%AF%E6%B3%95%EF%BC%89/">(no title)</a>
          </li>
        
          <li>
            <a href="/2025/06/11/data_structiure_and_algorithms_doc/algorithms_solution_doc/012-%E8%B7%B3%E8%B7%83%E6%B8%B8%E6%88%8F%E8%83%BD%E5%90%A6%E5%88%B0%E7%BB%88%E7%82%B9+%E6%9C%80%E5%B0%8F%E8%B7%B3%E8%B7%83%E6%AC%A1%E6%95%B0%EF%BC%88%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%EF%BC%89/">(no title)</a>
          </li>
        
          <li>
            <a href="/2025/06/11/data_structiure_and_algorithms_doc/algorithms_solution_doc/011-%E7%BB%84%E5%90%88%E6%80%BB%E5%92%8C%EF%BC%88%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2%EF%BC%88DFS%EF%BC%89%EF%BC%89/">(no title)</a>
          </li>
        
          <li>
            <a href="/2025/06/11/data_structiure_and_algorithms_doc/algorithms_solution_doc/010-%E4%B8%A4%E4%B8%A4%E4%BA%A4%E6%8D%A2%E9%93%BE%E8%A1%A8%E4%B8%AD%E8%8A%82%E7%82%B9%EF%BC%88%E5%93%91%E8%8A%82%E7%82%B9%EF%BC%89/">(no title)</a>
          </li>
        
          <li>
            <a href="/2025/06/11/data_structiure_and_algorithms_doc/algorithms_solution_doc/009-%E7%9B%9B%E6%9C%80%E5%A4%9A%E6%B0%B4%E7%9A%84%E5%AE%B9%E5%99%A8%EF%BC%88%E5%8F%8C%E6%8C%87%E9%92%88%EF%BC%89/">(no title)</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2025 EvelynUU<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>