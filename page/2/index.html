<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>✨✨✨ WOW, recorded a lot😶‍🌫️ ✨✨✨</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta property="og:type" content="website">
<meta property="og:title" content="✨✨✨ WOW, recorded a lot😶‍🌫️ ✨✨✨">
<meta property="og:url" content="http://example.com/page/2/index.html">
<meta property="og:site_name" content="✨✨✨ WOW, recorded a lot😶‍🌫️ ✨✨✨">
<meta property="og:locale">
<meta property="article:author" content="EvelynUU">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="✨✨✨ WOW, recorded a lot😶‍🌫️ ✨✨✨" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/fork-awesome@1.2.0/css/fork-awesome.min.css">

<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">✨✨✨ WOW, recorded a lot😶‍🌫️ ✨✨✨</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">Repeatings, Thoughts, and Writings</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Suche"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Suche"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main">
  
    <article id="post-ML_LLM_AI/python/pytorch/002-tensors-basic" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/01/12/ML_LLM_AI/python/pytorch/002-tensors-basic/" class="article-date">
  <time class="dt-published" datetime="2021-01-12T09:06:19.000Z" itemprop="datePublished">2021-01-12</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/ML-LLM-AI/">ML_LLM_AI</a>►<a class="article-category-link" href="/categories/ML-LLM-AI/Pytorch/">Pytorch</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/01/12/ML_LLM_AI/python/pytorch/002-tensors-basic/">002-tensors basic</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="section"># PyTorch 张量基础</span></span><br><span class="line"></span><br><span class="line"><span class="section">## 张量简介</span></span><br><span class="line">张量是一种特殊的数据结构，与数组和矩阵非常相似。在PyTorch中，我们使用张量对模型的输入和输出以及模型的参数进行编码。</span><br><span class="line"></span><br><span class="line"><span class="section">## 基本操作</span></span><br><span class="line"></span><br><span class="line"><span class="section">### 创建张量</span></span><br><span class="line"><span class="code">```python</span></span><br><span class="line"><span class="code">import torch</span></span><br><span class="line"><span class="code">import numpy as np</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code"># 从随机数据和全1数据创建张量</span></span><br><span class="line"><span class="code">shape = (2, 3)</span></span><br><span class="line"><span class="code">rand_tensor = torch.rand(shape)  # 随机张量</span></span><br><span class="line"><span class="code">ones_tensor = torch.ones(shape)  # 全1张量</span></span><br></pre></td></tr></table></figure>

<h3 id="张量属性"><a href="#张量属性" class="headerlink" title="张量属性"></a>张量属性</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Shape of tensor: <span class="subst">&#123;rand_tensor.shape&#125;</span>&quot;</span>)  <span class="comment"># 形状</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Datatype of tensor: <span class="subst">&#123;rand_tensor.dtype&#125;</span>&quot;</span>)  <span class="comment"># 数据类型</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Device tensor is stored on: <span class="subst">&#123;rand_tensor.device&#125;</span>&quot;</span>)  <span class="comment"># 存储设备</span></span><br></pre></td></tr></table></figure>

<h3 id="索引和切片"><a href="#索引和切片" class="headerlink" title="索引和切片"></a>索引和切片</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor = torch.ones(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">tensor[:, <span class="number">1</span>] = <span class="number">0</span>  <span class="comment"># 将第1列所有元素设为0</span></span><br></pre></td></tr></table></figure>

<h3 id="张量连接"><a href="#张量连接" class="headerlink" title="张量连接"></a>张量连接</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t1 = torch.cat([tensor, tensor, tensor], dim=<span class="number">1</span>)  <span class="comment"># 沿维度1连接</span></span><br></pre></td></tr></table></figure>

<h2 id="张量运算"><a href="#张量运算" class="headerlink" title="张量运算"></a>张量运算</h2><h3 id="元素级乘法"><a href="#元素级乘法" class="headerlink" title="元素级乘法"></a>元素级乘法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 两种等价写法</span></span><br><span class="line"><span class="built_in">print</span>(tensor.mul(tensor))  <span class="comment"># 方法形式</span></span><br><span class="line"><span class="built_in">print</span>(tensor * tensor)     <span class="comment"># 运算符形式</span></span><br></pre></td></tr></table></figure>

<h3 id="矩阵乘法"><a href="#矩阵乘法" class="headerlink" title="矩阵乘法"></a>矩阵乘法</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 两种等价写法</span></span><br><span class="line"><span class="built_in">print</span>(tensor.matmul(tensor.T))  <span class="comment"># 方法形式</span></span><br><span class="line"><span class="built_in">print</span>(tensor @ tensor.T)        <span class="comment"># 运算符形式</span></span><br></pre></td></tr></table></figure>

<h3 id="原地操作（In-place）"><a href="#原地操作（In-place）" class="headerlink" title="原地操作（In-place）"></a>原地操作（In-place）</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor.add_(<span class="number">5</span>)  <span class="comment"># 带_后缀的操作会修改原张量</span></span><br></pre></td></tr></table></figure>
<p>注意：原地操作可以节省内存，但在计算导数时可能会出现问题，因此不鼓励使用。</p>
<h2 id="与NumPy互转"><a href="#与NumPy互转" class="headerlink" title="与NumPy互转"></a>与NumPy互转</h2><h3 id="张量转NumPy数组"><a href="#张量转NumPy数组" class="headerlink" title="张量转NumPy数组"></a>张量转NumPy数组</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">t = torch.ones(<span class="number">5</span>)</span><br><span class="line">n = t.numpy()  <span class="comment"># 转为NumPy数组</span></span><br></pre></td></tr></table></figure>

<h3 id="NumPy数组转张量"><a href="#NumPy数组转张量" class="headerlink" title="NumPy数组转张量"></a>NumPy数组转张量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">n = np.ones(<span class="number">5</span>)</span><br><span class="line">t = torch.from_numpy(n)  <span class="comment"># 转为PyTorch张量</span></span><br></pre></td></tr></table></figure>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/01/12/ML_LLM_AI/python/pytorch/002-tensors-basic/" data-id="cmcaettml009sw8sdc8234s8g" data-title="002-tensors basic" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Pytorch/" rel="tag">Pytorch</a></li></ul>

    </footer>
  </div>
  
</article>



  
    <article id="post-ML_LLM_AI/python/pytorch/003-torch.autograd" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2021/01/14/ML_LLM_AI/python/pytorch/003-torch.autograd/" class="article-date">
  <time class="dt-published" datetime="2021-01-14T09:09:53.000Z" itemprop="datePublished">2021-01-14</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/ML-LLM-AI/">ML_LLM_AI</a>►<a class="article-category-link" href="/categories/ML-LLM-AI/Pytorch/">Pytorch</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="p-name article-title" href="/2021/01/14/ML_LLM_AI/python/pytorch/003-torch.autograd/">003-torch.autograd</a>
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="section"># PyTorch Autograd 详解</span></span><br><span class="line"></span><br><span class="line"><span class="section">## 背景介绍</span></span><br><span class="line"><span class="code">`torch.autograd`</span>是PyTorch的自动微分引擎，为神经网络训练提供支持。</span><br><span class="line"></span><br><span class="line">神经网络(NN)是在输入数据上执行的嵌套函数集合，这些函数由参数（权重和偏差）定义，在PyTorch中存储在张量中。</span><br><span class="line"></span><br><span class="line">训练NN分为两个步骤：</span><br><span class="line"><span class="bullet">1.</span> <span class="strong">**前向传播**</span>：NN对输出做出最佳猜测</span><br><span class="line"><span class="bullet">2.</span> <span class="strong">**反向传播**</span>：NN根据误差调整参数，收集误差导数并使用梯度下降优化参数</span><br><span class="line"></span><br><span class="line"><span class="section">## Autograd内部机理</span></span><br><span class="line"></span><br><span class="line">![<span class="string">Autograd流程示意图</span>](<span class="link">../../../images/torch001.png</span>)</span><br><span class="line"></span><br><span class="line">实现autograd依赖于两种数据类型：</span><br><span class="line"><span class="bullet">-</span> <span class="code">`Variable`</span>：包装tensor数据，包含额外属性：</span><br><span class="line"><span class="bullet">  -</span> <span class="code">`data`</span>：存储的tensor数据</span><br><span class="line"><span class="bullet">  -</span> <span class="code">`grad`</span>：存储梯度</span><br><span class="line"><span class="bullet">  -</span> <span class="code">`creator`</span>：创建此Variable的Function</span><br><span class="line"></span><br><span class="line">工作流程：</span><br><span class="line"><span class="bullet">1.</span> 输入Variable经过操作(operation)生成输出Variable</span><br><span class="line"><span class="bullet">2.</span> 每个操作自动生成对应的Function实例</span><br><span class="line"><span class="bullet">3.</span> 反向传播时，Function自动计算梯度并存储在grad属性中</span><br><span class="line"></span><br><span class="line"><span class="strong">**重要概念**</span>：</span><br><span class="line"><span class="bullet">-</span> 只有creator为null的变量（叶子节点）才能返回导数</span><br><span class="line"><span class="bullet">-</span> 中间变量的grad为0</span><br><span class="line"></span><br><span class="line"><span class="section">## 使用案例</span></span><br><span class="line"></span><br><span class="line"><span class="section">### 1. 基本梯度采集</span></span><br><span class="line"></span><br><span class="line"><span class="code">```python</span></span><br><span class="line"><span class="code">import torch</span></span><br><span class="line"><span class="code">import torchvision</span></span><br><span class="line"><span class="code">import numpy as np</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code"># 创建需要跟踪梯度的张量</span></span><br><span class="line"><span class="code">a = torch.tensor([2., 3.], requires_grad=True)</span></span><br><span class="line"><span class="code">b = torch.tensor([6., 4.], requires_grad=True)</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code"># 定义计算图</span></span><br><span class="line"><span class="code">Q = 3*a**3 - b**2</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code"># 反向传播（只能对标量输出）</span></span><br><span class="line"><span class="code">Q.sum().backward()  # 或使用 Q.backward(gradient=torch.tensor([1., 1.]))</span></span><br><span class="line"><span class="code"></span></span><br><span class="line"><span class="code"># 验证梯度</span></span><br><span class="line"><span class="code">print(9*a**2 == a.grad)  # tensor([True, True])</span></span><br><span class="line"><span class="code">print(-2*b == b.grad)    # tensor([True, True])</span></span><br></pre></td></tr></table></figure>

<h3 id="2-在神经网络中的应用"><a href="#2-在神经网络中的应用" class="headerlink" title="2. 在神经网络中的应用"></a>2. 在神经网络中的应用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载预训练模型</span></span><br><span class="line">model = torchvision.models.resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line">data = torch.rand(<span class="number">1</span>, <span class="number">3</span>, <span class="number">64</span>, <span class="number">64</span>)  <span class="comment"># 模拟输入图像</span></span><br><span class="line">labels = torch.rand(<span class="number">1</span>, <span class="number">1000</span>)     <span class="comment"># 模拟标签</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 前向传播</span></span><br><span class="line">prediction = model(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算损失并反向传播</span></span><br><span class="line">loss = (prediction - labels).<span class="built_in">sum</span>()</span><br><span class="line">loss.backward()  <span class="comment"># 自动计算梯度</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用优化器更新参数</span></span><br><span class="line">optim = torch.optim.SGD(</span><br><span class="line">    model.parameters(), </span><br><span class="line">    lr=<span class="number">1e-2</span>,      <span class="comment"># 学习率0.01</span></span><br><span class="line">    momentum=<span class="number">0.9</span>  <span class="comment"># 动量</span></span><br><span class="line">)</span><br><span class="line">optim.step()      <span class="comment"># 执行梯度下降</span></span><br></pre></td></tr></table></figure>

<h2 id="重要注意事项"><a href="#重要注意事项" class="headerlink" title="重要注意事项"></a>重要注意事项</h2><ol>
<li><code>backward()</code>只能对标量输出调用</li>
<li>中间变量的grad为0，只有叶子节点能获得梯度</li>
<li>优化器通过<code>.step()</code>方法更新参数</li>
<li>每次反向传播前需要清空梯度（可通过<code>optim.zero_grad()</code>实现）</li>
</ol>
<blockquote>
<p>提示：使用前需确保已安装torchvision（<code>pip install torchvision</code>）<br>&#96;&#96;&#96;</p>
</blockquote>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2021/01/14/ML_LLM_AI/python/pytorch/003-torch.autograd/" data-id="cmcaettmn009yw8sdgdlzg5g3" data-title="003-torch.autograd" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Pytorch/" rel="tag">Pytorch</a></li></ul>

    </footer>
  </div>
  
</article>



  


  <nav id="page-nav">
    
    <a class="extend prev" rel="prev" href="/">&laquo; zurück</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/59/">59</a><a class="extend next" rel="next" href="/page/3/">weiter &raquo;</a>
  </nav>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Kategorien</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/CNBC/">CNBC</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/DevOps/">DevOps</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/DevOps/Docker/">Docker</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/DevOps/Jenkins/">Jenkins</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/DevOps/Openshift/">Openshift</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/DevOps/kubernetes/">kubernetes</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Foundation/">Foundation</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Foundation/DB/">DB</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Foundation/OS/">OS</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Foundation/ProtocolAndBrowser/">ProtocolAndBrowser</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Frontend/">Frontend</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Frontend/CSS/">CSS</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Frontend/JavaScript/">JavaScript</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Frontend/React/">React</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Frontend/Sass/">Sass</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/ML-LLM-AI/">ML_LLM_AI</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/ML-LLM-AI/Pytorch/">Pytorch</a></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/Principles/">Principles</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/algorithms/">algorithms</a><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/algorithms/leetcode/">leetcode</a></li></ul></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list" itemprop="keywords"><li class="tag-list-item"><a class="tag-list-link" href="/tags/CNBC-Finance/" rel="tag">CNBC Finance</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/CSS/" rel="tag">CSS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/DB/" rel="tag">DB</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Docker/" rel="tag">Docker</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Javascript/" rel="tag">Javascript</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Jenkins/" rel="tag">Jenkins</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/OS/" rel="tag">OS</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Openshift/" rel="tag">Openshift</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Principles/" rel="tag">Principles</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/ProtocolAndBrowser/" rel="tag">ProtocolAndBrowser</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Pytorch/" rel="tag">Pytorch</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/React/" rel="tag">React</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Sass/" rel="tag">Sass</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/algorithms/" rel="tag">algorithms</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/k8s/" rel="tag">k8s</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/CNBC-Finance/" style="font-size: 10px;">CNBC Finance</a> <a href="/tags/CSS/" style="font-size: 18.89px;">CSS</a> <a href="/tags/DB/" style="font-size: 11.11px;">DB</a> <a href="/tags/Docker/" style="font-size: 10px;">Docker</a> <a href="/tags/Javascript/" style="font-size: 17.78px;">Javascript</a> <a href="/tags/Jenkins/" style="font-size: 10px;">Jenkins</a> <a href="/tags/OS/" style="font-size: 11.11px;">OS</a> <a href="/tags/Openshift/" style="font-size: 10px;">Openshift</a> <a href="/tags/Principles/" style="font-size: 10px;">Principles</a> <a href="/tags/ProtocolAndBrowser/" style="font-size: 16.67px;">ProtocolAndBrowser</a> <a href="/tags/Pytorch/" style="font-size: 13.33px;">Pytorch</a> <a href="/tags/React/" style="font-size: 14.44px;">React</a> <a href="/tags/Sass/" style="font-size: 12.22px;">Sass</a> <a href="/tags/algorithms/" style="font-size: 20px;">algorithms</a> <a href="/tags/k8s/" style="font-size: 15.56px;">k8s</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archiv</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/06/">June 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/05/">May 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/04/">April 2025</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/02/">February 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/01/">January 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/01/">January 2020</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">letzter Beitrag</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2025/06/20/devops/kubernetes/1%20core%20concepts/1.9%20Kube%20Pods/">1.9 Kube Pods</a>
          </li>
        
          <li>
            <a href="/2025/06/20/devops/kubernetes/1%20core%20concepts/1.8%20Kube%20Proxy/">1.8 Kube Proxy</a>
          </li>
        
          <li>
            <a href="/2025/06/20/devops/kubernetes/1%20core%20concepts/1.7%20Kubelet/">1.7 Kubelet</a>
          </li>
        
          <li>
            <a href="/2025/06/20/devops/kubernetes/1%20core%20concepts/1.6%20Kube%20Scheduler/">1.6 Kube Scheduler</a>
          </li>
        
          <li>
            <a href="/2025/06/20/devops/kubernetes/1%20core%20concepts/1.5%20Kube%20Controller%20Manager/">1.5 Kube Controller Manager</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2025 EvelynUU<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>